{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KByC9YAElJzX"
   },
   "source": [
    "# D5 : Introduce Convolutional Neural Networks\n",
    "\n",
    "Today we will learn how to make a Convolutional Neural Network (CNN) for classifying images in the CIFAR-10 dataset.\n",
    "\n",
    "To start with, we will briefly introduce\n",
    "\n",
    "\n",
    "*   why CNN for image classification\n",
    "\n",
    "*   CNN pipeline, convolutional layer, and max pooling layer\n",
    "\n",
    "*   CNN applications\n",
    "\n",
    "*   CIFAR-10 dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS_QKbWXTyI5"
   },
   "source": [
    "## Why CNN\n",
    "A convolutional neural network (CNN, or ConvNet), is an architecture commonly used for deep learning. The use of CNNs for deep learning has become increasingly popular due to three important factors:\n",
    "\n",
    "*   It eliminates the need for manual feature extraction, i.e., the features are learnt directly by the CNN.\n",
    "\n",
    "*   It produces state-of-the-art recognition results.\n",
    "\n",
    "*   CNNs can be retrained for new recognition tasks and allow for building on pre-existing networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaNr67uGMZ-L"
   },
   "source": [
    "A convolutional neural network can have tens or hundreds of layers that each learn to detect different features of an image. Filters are applied to each training image at different resolutions and the output of each convolved image is used as the input to the next layer. The filters can start as very simple features, such as brightness and edges, and increase in complexity to features that uniquely define the object as the layers progress.\n",
    "\n",
    "\n",
    "CNNs for Image classification:\n",
    "\n",
    "One method for creating a convolutional neural network to perform image classification is to train a network from scratch. The architect is required to define the number of layers, the learning weights, and number of filters, along with other tunable parameters. Training an accurate model from scratch also requires massive amounts of data, on the order of millions of samples, which can take an immense amount of time to train.\n",
    "\n",
    "A common alternative to training a CNN from scratch is to use a pre-trained model to automatically extract features from a new data set. This method, called transfer learning, is a convenient way to apply deep learning without a huge data set and long computation and training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-9Hzznxslr5"
   },
   "source": [
    "## CIFAR-10 database\n",
    "CIFAR-10 classification is a common benchmark problem in machine learning. The problem is to classify RGB 32*32 pixel images across 10 categories, i.e., airplane, automobile, bird, \n",
    "cat, deer, dog, frog, horse, ship, and truck. The CIFAR-10 dataset consists of 60000 images, with 6000 images per class. There are 50000 for training and the rest 10000 for test.\n",
    "For more details refer to the CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "in which, X_train, X_test are arrays of RBG image data with shape (num_samples, 3, 32, 32), and y_train, y_test are arrays of category labels (0-9) with shape (num_samples, 1).\n",
    "\n",
    "In PyTorch you can load CIFAR-10 with `torchvision.datasets.CIFAR10()`, which returns a datset for either the training or the test data, depending on the parameter `train=True` or `train=False`. Tha data hast the shape (num_samples, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2uf6Wsvpz0s"
   },
   "source": [
    "## Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kk1Jm0oh2KEJ",
    "outputId": "9312c4ab-c7e0-413d-d55d-5faeb00b4e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.3\n",
      "2.2.0+cu121\n",
      "0.17.0+cu121\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import BatchNorm2d, Conv2d, MaxPool2d, Flatten, Linear, Dropout\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(np.__version__)\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "# set up model to use GPU if available\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNC9rc4HTeew"
   },
   "source": [
    "## Exercise 1: Build a CNN with PyTorch for CIFAR-10 classification (with the following structure as depicted in the following figure)\n",
    "![cnn pipeline](https://cdn-images-1.medium.com/fit/t/1600/480/1*vkQ0hXDaQv57sALXAJquxA.jpeg)\n",
    "\n",
    "Steps: (No steps. First, brainstorm-time to build your own CNN)\n",
    "No need to implement the convolution computation, you may use `torch.nn.Conv2d` and `torch.nn.MaxPool2d` directly.\n",
    "But still, you need to set (initialise) weights and bias properly and give correct shapes of tensors to make it rock.\n",
    "\n",
    "### Your goal: more than 70% accuracy on the whole test set (be over 70% for 3+ epochs in a row).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171,
     "referenced_widgets": [
      "68adb56b01054aae800e0378d8283d54",
      "690e2a29318d4fd3ae76d9a58e9aafb0",
      "e164487f620c46afad375ac433481dbf",
      "51e3ba850f854eb1a2c818b34eff1596",
      "5b90f2e9f74d48cf9edc7d231e1cb4f7",
      "9077cf58190145678c1baca2317fa12b",
      "91f30ac6685d40fdb599df4e395f7dc2",
      "5f924aba3790451b9110d89b2b62ceb7",
      "cec8c60319c6475d926ef6646efbf106",
      "ae2cbaaf947a4fefbab97da0f38e9d2c",
      "57d81ba0474948d88e57d315a38fac2b"
     ]
    },
    "id": "xelDLaqv2KEN",
    "outputId": "b832711c-218b-4b2c-efe6-a164ff58ca46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 32, 32, 3]),\n",
       " torch.Size([50000]),\n",
       " torch.Size([10000, 32, 32, 3]),\n",
       " torch.Size([10000]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load the CIFAR-10 data\n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", \n",
    "    train=True, \n",
    "    transform=torchvision.transforms.ToTensor(), \n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\", \n",
    "    train=False, \n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "X_train, y_train = torch.tensor(train_data.data), torch.tensor(train_data.targets)\n",
    "X_test, y_test = torch.tensor(test_data.data), torch.tensor(test_data.targets)\n",
    "\n",
    "assert X_train.shape == (50000, 32, 32, 3)\n",
    "assert X_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000,)\n",
    "assert y_test.shape == (10000,)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A9pcoJSzpz00"
   },
   "source": [
    "## Provided code from the days before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EvpKCHE7pz00"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def single_model_step(\n",
    "    model: torch.nn.Module, \n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_function: typing.Callable,\n",
    "    training: bool,\n",
    "    X: torch.Tensor, \n",
    "    y: torch.Tensor,\n",
    "    device: str\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Single model training/evaluation step.\n",
    "\n",
    "    Args:\n",
    "        model: pytorch model to be trained\n",
    "        optimizer: optimizer wrapping pytorch model\n",
    "        loss_function: loss function\n",
    "        training: flag controlling whether this is a training\n",
    "            or an evaluation step\n",
    "        X: pytorch tensor containing features\n",
    "        y: pytorch tensor containing labels\n",
    "        device: device to where model is located\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: loss at current step\n",
    "    \"\"\"\n",
    "    pred = model(X.to(device))\n",
    "    loss = loss_function(pred, y.to(device))\n",
    "    if training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # return loss.cpu().item()\n",
    "    return loss.detach()\n",
    "\n",
    "# def inference_model(\n",
    "#     model: torch.nn.Module, \n",
    "#     loader: torch.utils.data.DataLoader,\n",
    "#     num_classes,\n",
    "#     device: str\n",
    "# ):\n",
    "#     r\"\"\"Evaluate model on dataloader.\n",
    "    \n",
    "#     Iterates over loader until it is exhausted \n",
    "#     and stores the model output (logits) and labels\n",
    "#     in tensors.\n",
    "    \n",
    "#     Args:\n",
    "#         model: model to be evaluated\n",
    "#         loader: dataloader containing data to evaluate model on\n",
    "#         device: string denoting device on which to run evaluation\n",
    "        \n",
    "#     Returns:\n",
    "#         torch.Tensor: model outputs (logits)\n",
    "#         torch.Tensor: ground truth labels\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     logits = torch.zeros((len(loader.dataset), num_classes))\n",
    "#     labels = torch.zeros((len(loader.dataset)))\n",
    "#     with torch.no_grad():\n",
    "#         for index, (X, y) in enumerate(loader):\n",
    "#             logits[index*BATCH_SIZE:(index+1)*BATCH_SIZE, :] = model(X.to(device)).cpu()\n",
    "#             labels[index*BATCH_SIZE:(index+1)*BATCH_SIZE] = y\n",
    "#     return logits, labels\n",
    "\n",
    "# def get_accuracy(labels, logits):\n",
    "#     r\"\"\"Compute accuracy.\n",
    "    \n",
    "#     Args:\n",
    "#         labels: ground truth labels\n",
    "#         logits: model predictions\n",
    "    \n",
    "#     Returns:\n",
    "#         torch.Tensor: single accuracy value\n",
    "#     \"\"\"\n",
    "#     prediction_indices = torch.argmax(logits, axis=-1)\n",
    "#     correct_predictions = labels == prediction_indices\n",
    "#     accuracy = correct_predictions.sum() / len(correct_predictions)\n",
    "#     return accuracy.item()\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(\n",
    "    model: torch.nn.Module, \n",
    "    loss_function: typing.Callable, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    num_classes: int,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "    verbose: bool,\n",
    "):\n",
    "    r\"\"\"Run training and evaluation.\n",
    "    \n",
    "    Args:\n",
    "        model: pytorch model to be trained\n",
    "        loss_function: loss function\n",
    "        optimizer: optimizer wrapping pytorch model\n",
    "        train_loader: dataloader containing training data\n",
    "        test_loader: dataloader containing training data\n",
    "        num_classes: number of classes for the classification task\n",
    "        epochs: number of epochs for which to train model\n",
    "        device: device to where model is located\n",
    "        verbose: flag controlling whether to print information\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: accuracy on test set after last epoch\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n---------- EPOCH {epoch + 1} ------------\")\n",
    "\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for train_steps, (X, y) in enumerate(train_loader):\n",
    "            train_loss += single_model_step(\n",
    "                model=model, \n",
    "                loss_function=loss_function, \n",
    "                optimizer=optimizer, \n",
    "                training=True,\n",
    "                X=X, \n",
    "                y=y,\n",
    "                device=device\n",
    "            )\n",
    "        train_loss /= train_steps\n",
    "        print(f\"Average Train Loss: {train_loss}\")\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_steps, (X, y) in enumerate(test_loader):\n",
    "                test_loss += single_model_step(\n",
    "                    model=model, \n",
    "                    loss_function=loss_function, \n",
    "                    optimizer=optimizer, \n",
    "                    training=False,\n",
    "                    X=X, \n",
    "                    y=y,\n",
    "                    device=device\n",
    "                )\n",
    "        test_loss /= test_steps\n",
    "        print(f\"Average Test Loss: {test_loss}\")\n",
    "\n",
    "        # logits, labels = inference_model(\n",
    "        #     model=model, \n",
    "        #     loader=test_loader,\n",
    "        #     num_classes=num_classes,\n",
    "        #     device=device\n",
    "        # )\n",
    "        # accuracy = get_accuracy(\n",
    "        #     labels=labels,\n",
    "        #     logits=logits\n",
    "        # )\n",
    "        model.eval()\n",
    "        accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for test_steps, (X, y) in enumerate(test_loader):\n",
    "                pred = model(X.to(device))\n",
    "                correct += torch.sum(torch.argmax(pred, axis=-1) == y.to(device)).item()\n",
    "                total += y.size(0)\n",
    "            accuracy = correct / total\n",
    "        print(f\"Test Accuracy: {accuracy}\")\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VdD-Pzsipz02"
   },
   "source": [
    "## Your turn, have fun! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax58kWh08rzU"
   },
   "source": [
    "Use the data loaders `train_loader` and `test_loader` from above for your training. The only thing you should have to do is to create your own model. For training and evaluating it you can simply use the provided functions from the last days (also incorporated above). Again a short reminder: you may use `torch.nn.Conv2d` and `torch.nn.MaxPool2d` directly. However, don't forget to set (initialise) weights and bias properly and give correct shapes of tensors.\n",
    "Achieve a test accuracy of more than 70% on the whole test set for 3+ epochs in a row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0mCXWJkD2KEQ"
   },
   "outputs": [],
   "source": [
    "# Use the data loaders `train_loader` and `test_loader` from above for your training. The only thing you should have to do is to create your own model. For training and evaluating it you can simply use the provided functions from the last days (also incorporated above). Again a short reminder: you may use `torch.nn.Conv2d` and `torch.nn.MaxPool2d` directly. However, don't forget to set (initialise) weights and bias properly and give correct shapes of tensors.\n",
    "# Achieve a test accuracy of more than 70% on the whole test set for 3+ epochs in a row.\n",
    "\n",
    "class MyModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_filters: int, # == num_pooling\n",
    "                 num_dense: int,\n",
    "                 input_shape_chw: torch.Size = torch.Size([3, 32, 32]),\n",
    "                 num_classes: int = 10\n",
    "                 ):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.num_filters = num_filters\n",
    "        self.num_dense = num_dense\n",
    "\n",
    "        self.conv_channels = 32\n",
    "        self.hidden_units = 64\n",
    "\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "\n",
    "        # Convolutional Layers and Pooling\n",
    "        last_chw = input_shape_chw\n",
    "        for i in range(num_filters):\n",
    "            # conv\n",
    "            self.layers.append(Conv2d(last_chw[0], self.conv_channels, kernel_size=5, padding='same'))\n",
    "            #torch.nn.init.kaiming_normal_(self.layers[-1].weight)\n",
    "            #torch.nn.init.zeros_(self.layers[-1].bias)\n",
    "            # conv activation\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "\n",
    "            # update shape\n",
    "            last_chw = torch.Size([self.conv_channels, last_chw[1], last_chw[2]])\n",
    "\n",
    "            # pooling\n",
    "            self.layers.append(MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "            # update shape\n",
    "            last_chw = torch.Size([self.conv_channels, last_chw[1]//2, last_chw[2]//2])\n",
    "\n",
    "        self.layers.append(Flatten())\n",
    "        last_chw = torch.prod(torch.tensor(last_chw)).item()\n",
    "\n",
    "        self.width_after_conv = last_chw\n",
    "\n",
    "        # dense layers\n",
    "        for i in range(num_dense):\n",
    "            self.layers.append(Linear(last_chw, self.hidden_units))\n",
    "            #torch.nn.init.kaiming_normal_(self.layers[-1].weight)\n",
    "            #torch.nn.init.zeros_(self.layers[-1].bias)\n",
    "\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "            last_chw = self.hidden_units\n",
    "\n",
    "        # output: logits\n",
    "        self.layers.append(Linear(last_chw, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x has shape (BATCH_SIZE, C, H, W)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 32, 32]) torch.Size([32, 10])\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "# test shapes\n",
    "model = MyModel(\n",
    "    num_filters=2,\n",
    "    num_dense=2,\n",
    ").to(device)\n",
    "\n",
    "x,y = next(iter(train_loader))\n",
    "x=x.to(device)\n",
    "y=y.to(device)\n",
    "print(x.shape, model(x).shape)\n",
    "print(model.width_after_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "\n",
      "---------- EPOCH 1 ------------\n",
      "Average Train Loss: 1.6564769744873047\n",
      "Average Test Loss: 1.387930989265442\n",
      "Test Accuracy: 0.4944\n",
      "\n",
      "---------- EPOCH 2 ------------\n",
      "Average Train Loss: 1.3082537651062012\n",
      "Average Test Loss: 1.1984745264053345\n",
      "Test Accuracy: 0.5767\n",
      "\n",
      "---------- EPOCH 3 ------------\n",
      "Average Train Loss: 1.141565203666687\n",
      "Average Test Loss: 1.0873587131500244\n",
      "Test Accuracy: 0.6142\n",
      "\n",
      "---------- EPOCH 4 ------------\n",
      "Average Train Loss: 1.034796953201294\n",
      "Average Test Loss: 1.0541261434555054\n",
      "Test Accuracy: 0.6382\n",
      "\n",
      "---------- EPOCH 5 ------------\n",
      "Average Train Loss: 0.9633280634880066\n",
      "Average Test Loss: 1.0510364770889282\n",
      "Test Accuracy: 0.6369\n",
      "\n",
      "---------- EPOCH 6 ------------\n",
      "Average Train Loss: 0.9064732193946838\n",
      "Average Test Loss: 0.9937820434570312\n",
      "Test Accuracy: 0.6574\n",
      "\n",
      "---------- EPOCH 7 ------------\n",
      "Average Train Loss: 0.8599566221237183\n",
      "Average Test Loss: 0.9324032664299011\n",
      "Test Accuracy: 0.6747\n",
      "\n",
      "---------- EPOCH 8 ------------\n",
      "Average Train Loss: 0.8251121044158936\n",
      "Average Test Loss: 0.9337704181671143\n",
      "Test Accuracy: 0.6732\n",
      "\n",
      "---------- EPOCH 9 ------------\n",
      "Average Train Loss: 0.7906718254089355\n",
      "Average Test Loss: 0.8847848176956177\n",
      "Test Accuracy: 0.6938\n",
      "\n",
      "---------- EPOCH 10 ------------\n",
      "Average Train Loss: 0.7627061605453491\n",
      "Average Test Loss: 0.8810217380523682\n",
      "Test Accuracy: 0.6914\n",
      "\n",
      "---------- EPOCH 11 ------------\n",
      "Average Train Loss: 0.7414590120315552\n",
      "Average Test Loss: 0.8778466582298279\n",
      "Test Accuracy: 0.7012\n",
      "\n",
      "---------- EPOCH 12 ------------\n",
      "Average Train Loss: 0.7151391506195068\n",
      "Average Test Loss: 0.8558793663978577\n",
      "Test Accuracy: 0.7042\n",
      "\n",
      "---------- EPOCH 13 ------------\n",
      "Average Train Loss: 0.702735424041748\n",
      "Average Test Loss: 0.8470812439918518\n",
      "Test Accuracy: 0.7088\n",
      "\n",
      "---------- EPOCH 14 ------------\n",
      "Average Train Loss: 0.6811904311180115\n",
      "Average Test Loss: 0.8705964088439941\n",
      "Test Accuracy: 0.6993\n",
      "\n",
      "---------- EPOCH 15 ------------\n",
      "Average Train Loss: 0.6666374802589417\n",
      "Average Test Loss: 0.8618130087852478\n",
      "Test Accuracy: 0.7079\n",
      "\n",
      "---------- EPOCH 16 ------------\n",
      "Average Train Loss: 0.6573215126991272\n",
      "Average Test Loss: 0.8776830434799194\n",
      "Test Accuracy: 0.7089\n",
      "\n",
      "---------- EPOCH 17 ------------\n",
      "Average Train Loss: 0.6390777230262756\n",
      "Average Test Loss: 0.928322434425354\n",
      "Test Accuracy: 0.6869\n",
      "\n",
      "---------- EPOCH 18 ------------\n",
      "Average Train Loss: 0.6286218166351318\n",
      "Average Test Loss: 0.8654308915138245\n",
      "Test Accuracy: 0.7147\n",
      "\n",
      "---------- EPOCH 19 ------------\n",
      "Average Train Loss: 0.6189934611320496\n",
      "Average Test Loss: 0.856382429599762\n",
      "Test Accuracy: 0.7128\n",
      "\n",
      "---------- EPOCH 20 ------------\n",
      "Average Train Loss: 0.6060127019882202\n",
      "Average Test Loss: 0.8511154055595398\n",
      "Test Accuracy: 0.7165\n",
      "\n",
      "---------- EPOCH 21 ------------\n",
      "Average Train Loss: 0.6033390164375305\n",
      "Average Test Loss: 0.8683949112892151\n",
      "Test Accuracy: 0.7076\n",
      "\n",
      "---------- EPOCH 22 ------------\n",
      "Average Train Loss: 0.5894798636436462\n",
      "Average Test Loss: 0.8538016676902771\n",
      "Test Accuracy: 0.7159\n",
      "\n",
      "---------- EPOCH 23 ------------\n",
      "Average Train Loss: 0.5850903987884521\n",
      "Average Test Loss: 0.8803860545158386\n",
      "Test Accuracy: 0.7112\n",
      "\n",
      "---------- EPOCH 24 ------------\n",
      "Average Train Loss: 0.5791968703269958\n",
      "Average Test Loss: 0.8496943116188049\n",
      "Test Accuracy: 0.717\n",
      "\n",
      "---------- EPOCH 25 ------------\n",
      "Average Train Loss: 0.563502311706543\n",
      "Average Test Loss: 0.8579347133636475\n",
      "Test Accuracy: 0.7164\n",
      "\n",
      "---------- EPOCH 26 ------------\n",
      "Average Train Loss: 0.5621189475059509\n",
      "Average Test Loss: 0.8782387971878052\n",
      "Test Accuracy: 0.7182\n",
      "\n",
      "---------- EPOCH 27 ------------\n",
      "Average Train Loss: 0.5515081286430359\n",
      "Average Test Loss: 0.8808556795120239\n",
      "Test Accuracy: 0.7123\n",
      "\n",
      "---------- EPOCH 28 ------------\n",
      "Average Train Loss: 0.5459509491920471\n",
      "Average Test Loss: 0.8542359471321106\n",
      "Test Accuracy: 0.717\n",
      "\n",
      "---------- EPOCH 29 ------------\n",
      "Average Train Loss: 0.5424882769584656\n",
      "Average Test Loss: 0.8907446265220642\n",
      "Test Accuracy: 0.7157\n",
      "\n",
      "---------- EPOCH 30 ------------\n",
      "Average Train Loss: 0.5355835556983948\n",
      "Average Test Loss: 0.8758485317230225\n",
      "Test Accuracy: 0.7154\n",
      "\n",
      "---------- EPOCH 31 ------------\n",
      "Average Train Loss: 0.530450701713562\n",
      "Average Test Loss: 0.8795865774154663\n",
      "Test Accuracy: 0.7118\n",
      "\n",
      "---------- EPOCH 32 ------------\n",
      "Average Train Loss: 0.5245565176010132\n",
      "Average Test Loss: 0.8583880066871643\n",
      "Test Accuracy: 0.7238\n",
      "\n",
      "---------- EPOCH 33 ------------\n",
      "Average Train Loss: 0.5222243070602417\n",
      "Average Test Loss: 0.8687193393707275\n",
      "Test Accuracy: 0.7166\n",
      "\n",
      "---------- EPOCH 34 ------------\n",
      "Average Train Loss: 0.515376627445221\n",
      "Average Test Loss: 0.8584698438644409\n",
      "Test Accuracy: 0.7247\n",
      "\n",
      "---------- EPOCH 35 ------------\n",
      "Average Train Loss: 0.5170446038246155\n",
      "Average Test Loss: 0.9956396222114563\n",
      "Test Accuracy: 0.6899\n",
      "\n",
      "---------- EPOCH 36 ------------\n",
      "Average Train Loss: 0.5119770169258118\n",
      "Average Test Loss: 0.87702876329422\n",
      "Test Accuracy: 0.7186\n",
      "\n",
      "---------- EPOCH 37 ------------\n",
      "Average Train Loss: 0.5049192309379578\n",
      "Average Test Loss: 0.8755384683609009\n",
      "Test Accuracy: 0.7175\n",
      "\n",
      "---------- EPOCH 38 ------------\n",
      "Average Train Loss: 0.5001775026321411\n",
      "Average Test Loss: 0.889555811882019\n",
      "Test Accuracy: 0.7226\n",
      "\n",
      "---------- EPOCH 39 ------------\n",
      "Average Train Loss: 0.49785545468330383\n",
      "Average Test Loss: 0.9033851623535156\n",
      "Test Accuracy: 0.7184\n",
      "\n",
      "---------- EPOCH 40 ------------\n",
      "Average Train Loss: 0.49523261189460754\n",
      "Average Test Loss: 0.8687070608139038\n",
      "Test Accuracy: 0.7221\n",
      "\n",
      "---------- EPOCH 41 ------------\n",
      "Average Train Loss: 0.49086326360702515\n",
      "Average Test Loss: 0.9415678381919861\n",
      "Test Accuracy: 0.7108\n",
      "\n",
      "---------- EPOCH 42 ------------\n",
      "Average Train Loss: 0.4884694516658783\n",
      "Average Test Loss: 0.8831418752670288\n",
      "Test Accuracy: 0.7209\n",
      "\n",
      "---------- EPOCH 43 ------------\n",
      "Average Train Loss: 0.48247143626213074\n",
      "Average Test Loss: 0.8923954367637634\n",
      "Test Accuracy: 0.7149\n",
      "\n",
      "---------- EPOCH 44 ------------\n",
      "Average Train Loss: 0.4801749885082245\n",
      "Average Test Loss: 0.9219637513160706\n",
      "Test Accuracy: 0.7156\n",
      "\n",
      "---------- EPOCH 45 ------------\n",
      "Average Train Loss: 0.482791930437088\n",
      "Average Test Loss: 0.9075144529342651\n",
      "Test Accuracy: 0.7194\n",
      "\n",
      "---------- EPOCH 46 ------------\n",
      "Average Train Loss: 0.475617915391922\n",
      "Average Test Loss: 0.9194332957267761\n",
      "Test Accuracy: 0.7141\n",
      "\n",
      "---------- EPOCH 47 ------------\n",
      "Average Train Loss: 0.47271716594696045\n",
      "Average Test Loss: 0.92886883020401\n",
      "Test Accuracy: 0.7126\n",
      "\n",
      "---------- EPOCH 48 ------------\n",
      "Average Train Loss: 0.4737774729728699\n",
      "Average Test Loss: 0.9400274157524109\n",
      "Test Accuracy: 0.7152\n",
      "\n",
      "---------- EPOCH 49 ------------\n",
      "Average Train Loss: 0.47112923860549927\n",
      "Average Test Loss: 0.9024748206138611\n",
      "Test Accuracy: 0.7139\n",
      "\n",
      "---------- EPOCH 50 ------------\n",
      "Average Train Loss: 0.4683385491371155\n",
      "Average Test Loss: 0.9212769865989685\n",
      "Test Accuracy: 0.714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train a new model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = MyModel(num_filters=4, num_dense=0).to(device)\n",
    "print(model.width_after_conv)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "train_and_evaluate(\n",
    "    model=model, \n",
    "    loss_function=loss_function, \n",
    "    optimizer=optimizer, \n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    num_classes=10,\n",
    "    epochs=50,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SevLyxhQsljC"
   },
   "source": [
    "## 2. Shape and number of parameters\n",
    "\n",
    "Compute the shapes of your convolutional and max pooling layers as well as the number of trainable parameters of your convolutions and fully-connected layers. Use the formulas below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxx9kxtnUkvO"
   },
   "source": [
    "### Formulas for the calculation of the shapes and trainable parameters\n",
    "\n",
    "#### Number of trainable parameters:\n",
    "\n",
    "n_params_dense = n_input*n_output + n_output  , i.e.: n_weight_matrix + n_bias\n",
    "\n",
    "\n",
    "n_params_conv = kernel_size_h \\* kernel_size_w \\* n_filters_in \\* n_filters_out + n_filters_out \n",
    "\n",
    "Every region of (kernelwidth x kernelheight x input_filters) shares weights. Output for every region is (n_filters_out), afterwards, bias is added, therefore + n_filters_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGZ8RKNoHZn0"
   },
   "source": [
    "#### Output shape of a concolutional layer:\n",
    "1. output_width = (input_width - kernel_size + 2 \\* amount_zero_padding) / stride + 1\n",
    "2. output_height = (input_height - kernel_size + 2 \\* amount_zero_padding) / stride + 1\n",
    "3. output_depth = n_filters\n",
    "\n",
    "#### Output shape of a max pooling layer:\n",
    "1. output_width = (input_width - kernel_size) / stride + 1\n",
    "2. output_height = (input_height - kernel_size) / stride + 1\n",
    "3. output_depth = n_filters\n",
    "\n",
    "If the result is a decimal point, it is rounded down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (layers): ModuleList(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "J3ALdWrPIemh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (c, h, w)\n",
      "(3, 32, 32)\n",
      "Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "(32, 32, 32)\n",
      "ReLU()\n",
      "(32, 32, 32)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "(32, 16, 16)\n",
      "Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "(32, 16, 16)\n",
      "ReLU()\n",
      "(32, 16, 16)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "(32, 8, 8)\n",
      "Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "(32, 8, 8)\n",
      "ReLU()\n",
      "(32, 8, 8)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "(32, 4, 4)\n",
      "Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "(32, 4, 4)\n",
      "ReLU()\n",
      "(32, 4, 4)\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "(32, 2, 2)\n",
      "Flatten(start_dim=1, end_dim=-1)\n",
      "128\n",
      "Linear(in_features=128, out_features=10, bias=True)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# calculate shapes and trainable parameters\n",
    "# output shape of Conv2D\n",
    "def get_outshape_conv2d(in_c, in_h, in_w, kernel_size, channels_out):\n",
    "    padding = (kernel_size-1)//2\n",
    "    stride = 1\n",
    "    out_c = channels_out\n",
    "    out_w = (in_w + 2*padding - kernel_size) // stride + 1\n",
    "    out_h = (in_h + 2*padding - kernel_size) // stride + 1\n",
    "    return out_c, out_h, out_w\n",
    "\n",
    "# output shape of MaxPool2d\n",
    "def get_outshape_maxpool2d(in_c, in_h, in_w, kernel_size):\n",
    "    stride = kernel_size\n",
    "    out_c = in_c\n",
    "    out_h = (in_h - kernel_size) // stride + 1\n",
    "    out_w = (in_w - kernel_size) // stride + 1\n",
    "    return out_c, out_h, out_w\n",
    "\n",
    "# output shape of Flatten\n",
    "def get_outshape_flatten(in_c, in_h, in_w):\n",
    "    return in_c * in_h * in_w\n",
    "\n",
    "# output shape of Linear\n",
    "def get_outshape_linear(in_features, out_features):\n",
    "    return out_features\n",
    "\n",
    "def print_shapes(model):\n",
    "    print(\"Shapes: (c, h, w)\")    \n",
    "    shape = (3, 32, 32)\n",
    "    for lay in model.layers:\n",
    "        print(shape)\n",
    "        if isinstance(lay, Conv2d):\n",
    "            shape = get_outshape_conv2d(shape[0], shape[1], shape[2], lay.kernel_size[0], lay.out_channels)\n",
    "        elif isinstance(lay, MaxPool2d):\n",
    "            shape = get_outshape_maxpool2d(shape[0], shape[1], shape[2], lay.kernel_size)\n",
    "        elif isinstance(lay, Flatten):\n",
    "            shape = get_outshape_flatten(shape[0], shape[1], shape[2])\n",
    "        elif isinstance(lay, Linear):\n",
    "            shape = get_outshape_linear(shape, lay.out_features)\n",
    "        else:\n",
    "            pass\n",
    "        print(lay)\n",
    "    print(shape)\n",
    "\n",
    "print_shapes(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2432 Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "         0 ReLU()\n",
      "         0 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "     25632 Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "         0 ReLU()\n",
      "         0 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "     25632 Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "         0 ReLU()\n",
      "         0 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "     25632 Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=same)\n",
      "         0 ReLU()\n",
      "         0 MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "         0 Flatten(start_dim=1, end_dim=-1)\n",
      "      1290 Linear(in_features=128, out_features=10, bias=True)\n",
      "Total: 80618\n"
     ]
    }
   ],
   "source": [
    "# calculate trainable parameters\n",
    "def print_parameters(model):\n",
    "    param_total = 0\n",
    "    for lay in model.layers:\n",
    "        if isinstance(lay, Conv2d):\n",
    "            param = lay.kernel_size[0] * lay.kernel_size[1] * lay.in_channels * lay.out_channels + lay.out_channels    \n",
    "        elif isinstance(lay, Linear):\n",
    "            param = lay.in_features * lay.out_features + lay.out_features\n",
    "        else:\n",
    "            param = 0\n",
    "        print(f\"{param:10} {lay}\")\n",
    "        param_total += param\n",
    "    print(f\"Total: {param_total}\")\n",
    "\n",
    "print_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9511b72e2f0dc8789a87876b871a2c068f47e3c15d5f47ed9d92a201978a3866"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "51e3ba850f854eb1a2c818b34eff1596": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae2cbaaf947a4fefbab97da0f38e9d2c",
      "placeholder": "​",
      "style": "IPY_MODEL_57d81ba0474948d88e57d315a38fac2b",
      "value": " 170498071/170498071 [00:01&lt;00:00, 88430967.72it/s]"
     }
    },
    "57d81ba0474948d88e57d315a38fac2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b90f2e9f74d48cf9edc7d231e1cb4f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f924aba3790451b9110d89b2b62ceb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68adb56b01054aae800e0378d8283d54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_690e2a29318d4fd3ae76d9a58e9aafb0",
       "IPY_MODEL_e164487f620c46afad375ac433481dbf",
       "IPY_MODEL_51e3ba850f854eb1a2c818b34eff1596"
      ],
      "layout": "IPY_MODEL_5b90f2e9f74d48cf9edc7d231e1cb4f7"
     }
    },
    "690e2a29318d4fd3ae76d9a58e9aafb0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9077cf58190145678c1baca2317fa12b",
      "placeholder": "​",
      "style": "IPY_MODEL_91f30ac6685d40fdb599df4e395f7dc2",
      "value": "100%"
     }
    },
    "9077cf58190145678c1baca2317fa12b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "91f30ac6685d40fdb599df4e395f7dc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae2cbaaf947a4fefbab97da0f38e9d2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cec8c60319c6475d926ef6646efbf106": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e164487f620c46afad375ac433481dbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f924aba3790451b9110d89b2b62ceb7",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cec8c60319c6475d926ef6646efbf106",
      "value": 170498071
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
