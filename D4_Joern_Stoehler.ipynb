{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IahgcTUG6_YI"
   },
   "source": [
    "In this exercise, you will code a neural network for classifying audio segements for five different syllables: 'a' (as in 'bar'), 'e' (as in 'bed'), 'i' (as in 'big'), 'o' (as in 'shop'), 'u' (as in 'look').\n",
    "\n",
    "Download and unzip the data from [here](https://drive.google.com/open?id=1mzoJ-l99yduGDs4we3iL1D3qssHFjbne) and listen to the different .wav files. \n",
    "\n",
    "As features, we will use the spectrograms extracted from each wav file, that look something like the image [here](https://drive.google.com/open?id=19vXRpeeNHt2wv0e9o3KvEKYjxQzqa1WK). The spectrogram is acquired by applying a Fourier transform on overlapping 25ms windows on the audio. The x-axis is the time, and the y-axis is the frequency.\n",
    "\n",
    "To upload the data into this notebook, follow the instructions of the **\"Prepare the data\"**-section below.\n",
    "\n",
    "To visualize more spectrograms, use the **\"Visualize spectrogram\"** cell below.\n",
    "\n",
    "Each wav file is one second, and the corresponding spectrogram is of shape \\[97, 201] (97 time steps, 201 frequencies). You don't have to know much about the Fourier transform and audio/signal processing in order to classify audio segments with a neural network. From now on, we can just assume every audio segment is represented by a sequence of 97 time steps, where at each time step we have 201 features, regardless of their meaning. \n",
    "\n",
    "Our model will use a simple recurrent layer / LSTM layer. To compute the logits, we will apply an additional fully connected layer on the state of the last time step. On the logits we will apply `softmax` and compute the `cross entropy loss`. \n",
    "\n",
    "We will be implementing our custom RNN cells, which are fed in a custom RNN Layer, already implemented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import typing\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the data and load it into the memory. Follow either the steps for your local python/jupyter notebook installation or the steps for google colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for your local jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using jupyter notebook on your local machine, download the vowels.zip file, extract it, and set the path of the 'basefolder' variable to the vowels-directory. E.g. basefolder = \"home/user/DeepLearningPraktikum/Exercise4/vowels/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basefolder = \"\" #TODO Where you extracted the data, leave empty in Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps for google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using google colab there are a few possibilities for you to upload the vowels-data into the colab notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possibility 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the code in the cell below to load the vowels.zip file into your colab-notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O vowels.zip \"https://drive.google.com/uc?export=download&id=1mzoJ-l99yduGDs4we3iL1D3qssHFjbne\" && unzip vowels.zip -d vowels && rm vowels.zip\n",
    "\n",
    "basefolder = \"vowels\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possibility 2\n",
    "1. Upload the extracted vowels folder to your google drive.\n",
    "2. Mount your drive to collaboratory by using the cell below\n",
    "3. Now, set the basefolder-variable to the path in your drive where the vowels-folder is located. E.g. basefolder = \"/content/drive/MyDrive/vowels\" or something like basefolder = \"/content/vowels\". One way to find out the path to the vowel-folder is by having a look at the files in the panel on the left side of your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount your google drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set the basefolder-path\n",
    "basefolder = \"\" #TODO Where your data is located in your drive, leave empty if you are using your local jupyter notebook or already did option 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get acquainted to the data by listening to the audio files, looking at the spectrogram depicted below and by investigating the code for data preparation below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import typing\n",
    "from matplotlib import pyplot as plt\n",
    "# basefolder = \"~/vowels/\"\n",
    "\n",
    "audio = 'a/8.npy'\n",
    "mag = np.load(os.path.join(basefolder, audio))\n",
    "mag = 20.*np.log10(np.abs(mag)/10e-6) # amplitude to decibel\n",
    "\n",
    "plt.figure(figsize=(15, 7.5))\n",
    "plt.imshow(np.transpose(mag), origin=\"lower\", aspect=\"auto\", cmap='jet', interpolation=\"none\")\n",
    "plt.colorbar()\n",
    "\n",
    "plt.xlabel(\"time (s)\")\n",
    "plt.ylabel(\"frequency (hz)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the data before training the neural network\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import typing\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "def load_folder(fold):\n",
    "    features = []\n",
    "    for fl in os.listdir(basefolder + fold):\n",
    "        if fl.endswith('.npy'):\n",
    "            features.append(np.load(basefolder + fold + '/' + fl))\n",
    "    return np.stack(features)\n",
    "\"\"\"\n",
    "\n",
    "def load_folder(fold):\n",
    "    features = []\n",
    "    for fl in os.listdir(os.path.join(basefolder, fold)):\n",
    "        if fl.endswith('.npy'):\n",
    "            features.append(np.load(os.path.join(basefolder, fold, fl)))\n",
    "    return np.stack(features)\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "test_features = [] \n",
    "test_labels = []\n",
    "for i, vowel in enumerate('aeiou'):\n",
    "    features = load_folder(vowel)\n",
    "    nexamples = len(features)\n",
    "    labels = [i] * nexamples\n",
    "    l = int(0.8 * nexamples)\n",
    "    train_features.append(features[:l]) \n",
    "    train_labels.append(labels[:l])\n",
    "    test_features.append(features[l:]) \n",
    "    test_labels.append(labels[l:])\n",
    "X_train = np.concatenate(train_features)\n",
    "y_train = np.concatenate(train_labels)\n",
    "X_test = np.concatenate(test_features)\n",
    "y_test = np.concatenate(test_labels)\n",
    "\n",
    "##### torch\n",
    "X_train = torch.from_numpy(X_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "  \n",
    "print (X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use the variables `X_train`, `y_train`, `X_test` and `y_test` to create datasets (`torch.utils.data.TensorDataset`) and dataloaders. Use a batch_size of 32 for the dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Have a look at the implementation of the MyRNNLayer, which is used to wrap different types of RNNCells in a recurrent manner. The RNNLayer can be initialised either to output a sequence, i.e., to forward one output for each element of the sequence to the next layer, or to forward only one output at the last element of the sequence to the next layer. This has no effect on the calculation of the hidden state or cell state, but only affects, which values are used as an output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNNLayer(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        rnn_cell: torch.nn.Module, \n",
    "        return_sequence=False\n",
    "    ):\n",
    "        r\"\"\"RNN Constructor.\n",
    "\n",
    "        Args:\n",
    "            rnn_cell: the cell of the rnn defining how inputs are processed \n",
    "            return_sequence: flag controlling whether the ouput is a sequence or single elemnt\n",
    "        \"\"\"\n",
    "        super(MyRNNLayer, self).__init__()\n",
    "        self.return_sequence = return_sequence\n",
    "        self.rnn_cell = rnn_cell\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        r\"\"\"Processes the incoming sequence according to the RNNcell.\n",
    "\n",
    "        Args:\n",
    "            x: pytorch tensor containing a sequence features \n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: output of the RNN, either 2D (no sequence) or 3D (sequence) \n",
    "        \"\"\"\n",
    "        cell = self.rnn_cell.zero_hidden()\n",
    "        hidden_states = torch.zeros(x.shape[0], x.shape[1], self.rnn_cell.hidden_features)\n",
    "        for i in range(x.shape[1]):\n",
    "            hidden, cell  = self.rnn_cell(x[:,i,:], cell)\n",
    "            hidden_states[:,i,:] = hidden\n",
    "        if self.return_sequence:\n",
    "            return hidden_states\n",
    "        else:\n",
    "            return hidden\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Implement the MinimalRNNCell, i.e., the methods `__init__`, initialising all parameters of the cell (you can use the function `torch.nn.init.kaiming_uniform_(self.bias)`), the `zero_hidden` method, which initialises the hidden state of the cell as zero and the `forward` method. The `forward` method processes the transition for a single step in a sequence of intputs. It takes the $i$th input from the previous layer $x_i$ (e.g. input layer) and the hidden state of the previous step $c_{i-1}$, and computes the state and output for the current step $c_i, h_i$. For a simple recurrent network, the output and the state of of a given time step are the same. The transition for a single time step is given by: $c_i = h_i = \\text{tanh}(x_i W_x + h_{i-1} W_h + b)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimalRNNCell(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        hidden_features:int,\n",
    "        device:str\n",
    "    ):\n",
    "        r\"\"\"Simple RNN Cell Constructor.\n",
    "        \n",
    "        Args:\n",
    "            in_features: number of input features (in each sequence) \n",
    "            hidden_features: number of features in the hidden state\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # TODO Parameter initialisation\n",
    "                \n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        c: torch.Tensor\n",
    "    )-> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        r\"\"\"Processes the incoming input and previous cell state for one step in the sequence.\n",
    "\n",
    "        Args:\n",
    "            x: pytorch tensor containing an element of the input sequence\n",
    "            c: pytorch tensor containing the previous cell state\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor, torch.Tensor): output to the next layer (vert), and cell state (for next sequence elemnt) \n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO Define forward pass for one step of the sequence\n",
    "        return output, output\n",
    "        \n",
    "    def zero_hidden(\n",
    "        self\n",
    "    )-> torch.Tensor:\n",
    "        r\"\"\"Initialises cell state with zeros. Assign the hidden state to the model device (necessary when using GPU)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: cell state initialised with zeros  \n",
    "        \"\"\"\n",
    "\n",
    "        # TODO Return initial hidden state with zeros, consider the necessary shape (remember broadcasting)!\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Implement your own RNN model below. The model should consist of one RNN layer with a minimal RNN cell with a hidden layer size of 128, followed by a dense classification layer with 5 outputs according to the 5 classes. Use a `torch.nn.Linear` layer as a classification layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_size:int, \n",
    "        hidden_size:int, \n",
    "        output_size:int,\n",
    "        device:str\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # TODO: Define Cells and Layers \n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x\n",
    "    ):\n",
    "        # TODO: Implement forward\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are suggested solutions for the implementation of the routine for training and evaluation, and all necessary functions following yesterday's examples. The functions should be ready to run.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_step(\n",
    "    model: torch.nn.Module, \n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    loss_function: typing.Callable,\n",
    "    training: bool,\n",
    "    X: torch.Tensor, \n",
    "    y: torch.Tensor,\n",
    "    device: str\n",
    ") -> torch.Tensor:\n",
    "    r\"\"\"Single model training/evaluation step.\n",
    "\n",
    "    Args:\n",
    "        model: pytorch model to be trained\n",
    "        optimizer: optimizer wrapping pytorch model\n",
    "        loss_function: loss function\n",
    "        training: flag controlling whether this is a training\n",
    "            or an evaluation step\n",
    "        X: pytorch tensor containing features\n",
    "        y: pytorch tensor containing labels\n",
    "        device: device to where model is located\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: loss at current step\n",
    "    \"\"\"\n",
    "    pred = model(X.to(device))\n",
    "    loss = loss_function(pred, y.to(device))\n",
    "    if training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss.cpu().item()\n",
    "\n",
    "def inference_model(\n",
    "    model: torch.nn.Module, \n",
    "    loader: torch.utils.data.DataLoader,\n",
    "    num_classes,\n",
    "    device: str\n",
    "):\n",
    "    r\"\"\"Evaluate model on dataloader.\n",
    "    \n",
    "    Iterates over loader until it is exhausted \n",
    "    and stores the model output (logits) and labels\n",
    "    in tensors.\n",
    "    \n",
    "    Args:\n",
    "        model: model to be evaluated\n",
    "        loader: dataloader containing data to evaluate model on\n",
    "        device: string denoting device on which to run evaluation\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: model outputs (logits)\n",
    "        torch.Tensor: ground truth labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    logits = torch.zeros((len(loader.dataset), num_classes))\n",
    "    labels = torch.zeros((len(loader.dataset)))\n",
    "    batch_size = loader.batch_size\n",
    "    with torch.no_grad():\n",
    "        for index, (X, y) in enumerate(loader):\n",
    "            logits[index*batch_size:(index+1)*batch_size, :] = model(X.to(device)).cpu()\n",
    "            labels[index*batch_size:(index+1)*batch_size] = y\n",
    "    return logits, labels\n",
    "\n",
    "#logits, labels = inference_model(model, test_loader, 5, device)\n",
    "def get_accuracy(labels, logits):\n",
    "    r\"\"\"Compute accuracy.\n",
    "    \n",
    "    Args:\n",
    "        labels: ground truth labels\n",
    "        logits: model predictions\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: single accuracy value\n",
    "    \"\"\"\n",
    "    prediction_indices = torch.argmax(logits, axis=-1)\n",
    "    correct_predictions = labels == prediction_indices\n",
    "    accuracy = correct_predictions.sum() / len(correct_predictions)\n",
    "    return accuracy.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(\n",
    "    model: torch.nn.Module, \n",
    "    loss_function: typing.Callable, \n",
    "    optimizer: torch.optim.Optimizer, \n",
    "    train_loader: torch.utils.data.DataLoader,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    "    num_classes: int,\n",
    "    epochs: int,\n",
    "    device: str,\n",
    "    verbose: bool,\n",
    "):\n",
    "    r\"\"\"Run training and evaluation.\n",
    "    \n",
    "    Args:\n",
    "        model: pytorch model to be trained\n",
    "        loss_function: loss function\n",
    "        optimizer: optimizer wrapping pytorch model\n",
    "        train_loader: dataloader containing training data\n",
    "        test_loader: dataloader containing training data\n",
    "        num_classes: number of classes for the classification task\n",
    "        epochs: number of epochs for which to train model\n",
    "        device: device to where model is located\n",
    "        verbose: flag controlling whether to print information\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: accuracy on test set after last epoch\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for train_steps, (X, y) in enumerate(train_loader):\n",
    "            train_loss += single_model_step(\n",
    "                model=model, \n",
    "                loss_function=loss_function, \n",
    "                optimizer=optimizer, \n",
    "                training=True,\n",
    "                X=X, \n",
    "                y=y,\n",
    "                device=device\n",
    "            )\n",
    "        train_loss /= (train_steps + 1)\n",
    "        \n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for test_steps, (X, y) in enumerate(test_loader):\n",
    "                test_loss += single_model_step(\n",
    "                    model=model, \n",
    "                    loss_function=loss_function, \n",
    "                    optimizer=optimizer, \n",
    "                    training=False,\n",
    "                    X=X, \n",
    "                    y=y,\n",
    "                    device=device\n",
    "                )\n",
    "        test_loss /= test_steps\n",
    "        \n",
    "        logits, labels = inference_model(\n",
    "                model=model, \n",
    "                loader=test_loader,\n",
    "                num_classes=num_classes,\n",
    "                device=device\n",
    "            )\n",
    "        accuracy = get_accuracy(\n",
    "            labels=labels,\n",
    "            logits=logits\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n---------- EPOCH {epoch + 1} ------------\")\n",
    "            print(f\"Average Train Loss: {train_loss}\")\n",
    "            print(f\"Average Test Loss: {test_loss}\")\n",
    "            \n",
    "        \n",
    "            print(f\"Test Accuracy: {accuracy}\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Instantiate your own RNN model, then run the train_and_evaluate function implemented above using a cross entropy loss function, an Adam optimiser with `0.001` learning rate for 40 epochs. Finally, create a confusion matrix, a table that lists how often samples of the classes were predicted to be within any of the (other) classes. You can use an `sklearn` implementation. Note: We recommend using the CPU for training in today's exercise sheet as the models are fast to train with CPU as well and you do not risk running out of GPU resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed = 42\n",
    "device = 'cpu'\n",
    "\n",
    "# Instantiate model and run training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Model Architecture\n",
    "\n",
    "8. Complete the the `LSTMCell` class below. Now, use this recurrent cell with a hidden layer size of 128 instead of the previous `MinimalRNNCell` for a new RNN class. The `forward` method shall return the new cell output and the new cell state(s). Train your model for 50 epochs with an Adam optimiser and learning rate equal to 0.01. The implementation of `MyRNN2` should be very similar to `myRNN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMCell(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_features: int, \n",
    "        hidden_features: int,\n",
    "        device:str\n",
    "    ):\n",
    "        r\"\"\"LSTM Cell Constructor.\n",
    "        \n",
    "        Args:\n",
    "            in_features: number of input features (in each sequence) \n",
    "            hidden_features: number of features in the hidden and cell state, respectively\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Initialise Parameters\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        c: (torch.Tensor, torch.Tensor)\n",
    "    )-> typing.Tuple[torch.Tensor, typing.Tuple[torch.Tensor, torch.Tensor]]:\n",
    "        r\"\"\"Processes the incoming input and previous cell state for one step in the sequence.\n",
    "\n",
    "        Args:\n",
    "            x: pytorch tensor containing an element of the input sequence\n",
    "            c: tuple of pytorch tensors containing the previous hidden and cell state\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor, (torch.Tensor, torch.Tensor)): \\\n",
    "            output to the next layer (vert), and hidden and cell state (for next sequence elemnt) \n",
    "        \"\"\"\n",
    "        # Define forward\n",
    "        pass\n",
    "        \n",
    "    def zero_hidden(\n",
    "        self, \n",
    "    )-> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
    "        r\"\"\"Initialises cell state with zeros. Assign the hidden state to the model device (necessary when using GPU)\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor, torch.Tensor): cell and hidden state initialised with zeros  \n",
    "        \"\"\"\n",
    "        # TODO Return initial hidden state with zeros, consider the necessary shape (remember broadcasting)!\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN2(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_size:int, \n",
    "        hidden_size:int, \n",
    "        output_size:int,\n",
    "        device:str\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # TODO: Define Cells and Layers \n",
    "    \n",
    "    def forward(\n",
    "        self, \n",
    "        x\n",
    "    ):\n",
    "        # TODO: Implement forward\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Add more recurrent layers. The second recurrent layer takes as input the output sequence from the first recurrent layer, and so on. That is, make sure each recurrent layer returns the full sequence instead of only the last output. Train your network as in the previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Hyperparameters are all parameters of your model that you define a priori and that will not be tuned/learned during training. Examples are: learning rate, batch size, optimizer, size of the hidden layer or number of hidden layers. Explore the hyperparameter space to find a better performance. You can run for instance a grid search with wisely chosen hyperparameters and hyperparameters. Can you get a test accuracy beyond 85%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise4-rnn-solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
